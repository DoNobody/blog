# 人工智能基础

## 基础

### 线性代数

* 线性代数是用虚拟数字世界表示真实物理世界的工具。
  * 标量
  * 向量
    * 范数：向量的大小
    * 内积：两个向量间的关系
  * 矩阵
  * 张量

#### 线性空间

* 正交基
  * $Ax = y$
  * 特征值
  * 特征向量
  * 矩阵特征值和特征向量的动态意义在于表示了变化的速度和方向

### 概率论

* 贝叶斯定理
  $$P(H|D)=\frac{P(D|H)*P(H)}{P(D)}$$
  $P(H)$ 先验概率：预先设定的假设成立的概率
  $P(D|H)$ 似然概率：假设成立的前提下观测到结果的概率
  $P(H|D)$ 后验概率：即观测到结果的前提下假设成立的概率
* 概率估计：
  * 最大似然估计法（maximum likelihood estimation):
    * 最大似然估计法的思想是使训练数据出现的概率最大化，依此确定概率分布中的未知参数，估计出的概率分布也就最符合训练数据的分布
    * 最大似然估计法只需要使用训练数据
  * 最大后验概率法（maximum a posteriori estimation）:
    * 最大后验概率法的思想则是根据训练数据和已知的其他条件，使未知参数出现的可能性最大化，并选取最可能的未知参数取值作为估计值
    * 最大后验概率法除了数据外还需要额外的信息，就是贝叶斯公式中的先验概率
* 随机变量
  * 离散型随机变量
  * 连续型随机变量
* 概率质量函数
  * 概率质量函数
  * 概率密度函数
* 分布的类型：
  * 两点分布
  * 二项分布
  * 泊松分布
  * 均匀分布
  * 指数型分布
  * 正态分布
    * $$f(x) = \frac{1}{\sqrt{2\pi\theta}}\cdot -\frac{(x-y)^2}{2\sigma ^2} $$
* 数据特征
  * 数学期望（expected value)
  * 方差（variance）
  * 协方差（covariance)

### 数理统计

* 方法论：
  * 数理统计的任务是根据可观察的样本反过来推断总体的性质；
  * 推断的工具是统计量，统计量是样本的函数，是个随机变量；
  * 参数估计通过随机抽取的样本来估计总体分布的未知参数，包括点估计和区间估计；
  * 假设检验通过随机抽取的样本来接受或拒绝关于总体的某个判断，常用于估计机器学习模型的泛化错误率
* 参数估计（estimation theory）
  * 点估计
    * 矩估计法（methon of moments)
    * 最大似然估计法（maximum likelihood estimation)
      * 既然抽样得到的是已有的样本值，就可以认为取到这一组样本值的概率较大，因而在估计参数 θ 的时候就需要让已有样本值出现的可能性最大
      * 在已知样本数据及其分布的条件下，找到使样本数据以最大概率出现的假设。
  * 区间估计
    * 置信区间
    * 区间估计相当于在点估计的基础上进一步提供了取值范围和误差界限，分别对应着置信区间和置信水平
  * 评价
    * 无偏性，有效性，一致性
* 假设检验（hypothesis test）
  * 假设检验的作用就在于根据学习器在测试集上的性能推断其泛化能力的强弱，并确定所得结论的精确程度，可以进一步推广为比较不同学习器的性能
  * 泛化误差的构成可以分为三部分：偏差（bias）、方差（variance）和噪声（noise）

### 最优化

#### 目标函数

#### 约束条件

* 约束优化
  * 线性规划
  * 拉格朗日乘子（将约束优化转换为无约束优化）
    * $$L(x,y,\lambda) = f(x,y) + \lambda\varphi(x,y)$$
* 无约束优化

#### 优化方法

* 线性搜索法
  * 梯度下降法
    > 多元函数沿其负梯度方向下降最快
    * 批处理模式
    * 随机梯度下降法
  * 牛顿法
    * 使用泰勒公式展开
* 置信域方法
  * 先步长，后方向
* 启发式算法
  * 遗传算法
  * 模拟退火算法
  * 蚁群算法
  * 神经网络算法
  
### 信息论

#### 熵

> **熵的本质：一个系统内在的混乱程度**

* 信源熵
* 条件熵
* 信息增益（互信息）
* 信息增益比
* KL散度：用于描述两个概率分布之间的差异。
  * 非负性
  * 非对称性
* 最大熵原理：分类问题中的常用准则
  * 最大熵模型

### 形式逻辑

* 数据结果
* 处理算法

#### 一阶谓词逻辑

* 命题逻辑
* 谓词逻辑
  * 个体词
  * 谓词
    * 否定
    * 合取
    * 析取
    * 蕴涵
    * 等价
  * 量词
* 如果将认知过程定义为符号的逻辑运算，人工智能的基础就是形式逻辑。
* 谓词逻辑是知识表示的形式逻辑
* 基于谓词逻辑系统可以实现具有自动推荐能力的人工智能
* 不完备性定理 挑战：“认知的本质是计算”

### 机器学习

> 机器学习是计算机基于数据构建概率统计模型并运用模型对数据进行预测分析的学科

#### 输入输出分类

* 分类问题
* 回归问题
* 标注问题

#### 误差

* 训练误差
* 测试误差
* 误差程度
  * 过拟合
  * 欠拟合
* 交叉验证

#### 机器学习任务

* 监督学习
  * 生成方法
  * 判别方法
* 无监督学习
* 半监督学习
  
### 线性回归

> 线性回归假设输出变量是若干输入变量的线性组合，并根据这一关系求解线性组合中的最优系数
$$f(x) = w^Tx = \sum_{i=0}^n w_i \cdotp x_i$$
> 在训练集上确定系数$w_i$时，预测输出$f(x)$和真实输出$y$之间的误差是关注的核心指标。

* 线性回归：均方差
* 二维平面：欧几里得距离

#### 最小二乘法

* 利用正态分布以及最大似然估计求得

#### 线性回归正则化

> 抑制过拟合

* 岭回归（参数衰减）
* LASSO 回归（最小绝对缩减和选择算子）
  * 引入了稀疏性

### 朴素贝叶斯方法

> 根据训练数据计算后验概率，基于后验概率选择最佳决策

### 逻辑回归

> 逻辑回归模型是对线性回归的改进，用于解决分类问题
> 逻辑回归输出的是实例属于每个类别的似然概率，似然概率最大的类别就是分类结果
> 在一定条件下，逻辑回归模型与朴素贝叶斯分类器是等价的
> 多分类问题是可以通过多次二分类逻辑回归或者使用Softmax回归解决

### 决策树

> 决策树算法采用树形结构，使用层层推理来实现最终的分类。适合探索式的知识发现。

* 特征选择
  * 信息增益
* 决策树生成
  > *特征选择指标 信息增益、信息增益比、基尼系数
  * ID3算法，C4.5算法
  * cart算法（分类与回归树)(二叉树模型)
    * 找到基尼系数最小的分支
* 决策树剪裁
  * 预剪枝
  * 后剪枝

### 支持向量机

> 线性可分支持向量机通过硬间隔最大化求出划分超平面  
> 线性支持向量机通过软间隔最大化求出划分超平面  
> 非线性支持向量机利用核函数实现从低维原始空间到高维特征空间的转换，在高维空间上解决非线性分类问题。

#### 常用的核函数

* 线性核
* 多项式核
* 高斯核
* 拉普拉斯核
* Sigmoid核
> 支持向量机的学习是个凸二次规划问题，可以用SMO(序列最小最优化)算法快速求解

### 集成学习

#### 分类

* 序列化学习
  * Boosting机制，通过重复使用概率分布不同的训练数据完成集成，可以降低泛化误差中的偏差
  * 典型方法：自适应提升方法(Adaptive Boosting) AdaBoost
    > 先通过改变训练数据的分布权重，训练出具有一系列具有粗糙规则的弱个体分类器，再基于这些弱分类器进行反复学习和组合，构造出具有精细规则的强分类器。
    > 主要问题：训练数据权重调整的策略，弱分类器结果的组合策略
    > 能力：随着训练过程的深入，弱学习器的训练重心逐渐被自动调整到分类器错误的样本上，进一步学习优化。
* 并行化学习
  * Bagging机制，通过在训练数据中多次自助抽取不同的采样子集实现集成，可以降低泛化误差中的方差
  * 典型方法：随机森林方法
    >每棵决策树在选择划分属性时，首先从结点的属性集合中随机抽取出包含$K$个属性的一个子集，再在这个子集中选择最优的划分属性生成决策树

### 聚类分析

> 聚类分析是一种无监督学习方法，其目标是学习没有标签的训练样本，以揭示数据的内在性质和规律

#### 距离测度

* 非负性，同一性，对称性，直递性
* 闵可夫斯基距离

$$dist_{mk}(X_i,X_j) = (\sum^N_{n=1}|x_{in} - x_{jn}|^p)^{\frac{1}{p}}$$
> 欧式距离：p = 2

#### 常用的聚类方式

* 层次聚类
  * 汇聚方式
    * 单链接算法
    * 全链接算法
    * 均链接算法
* 原型聚类
  * K均值算法
    * 贪心策略
    * （取平均 - 重新计算中心 - 重新聚类）
* 分布聚类
    > 基于概率模型的聚类，假定隐藏的类别是数据空间上的一个分布。
  * 即进行参数估计，估计出的参数使似然函数最大化
    * 期望极大算法（EM）
      * 期望
      * 最大化
* 密度聚类
  > 样本分布的密度能决定分类的结构
  * DBSCAN（基于密度的空间聚类）

#### 应用

* 对用户进行分组

### 降维分析

#### 主成分分析

* 确定以何种标准确定属性的保留还是丢失，以及度量降维之后的信息损失
* 步骤
  * 数据规范化
  * 协方差矩阵计算
  * 特征值分解
  * 降维处理
  * 数据投影
* 不是特征选取，而是利用原始特征之间的相关性重新构造出新的特征(线性变换)
* 线性空间：超平面上尽可能分散，样本点到超平面上的距离尽可能小
* 经验方法
  * 保留所有大于1的特征值，以其对应的特征向量进行坐标转化

#### 特征选择

  > 搜索新的特征子集和对搜索结果进行评估
* 方法
  * 包裹法
  * 过滤法
  * 嵌入法
* 使用：
  * LASSO方法：引入 $L_1$ 范式作为正则项

#### 人工神经网络

### 感知器

* 感知器是一种二分类的监督学习算法，通过自适应调整权重解决线性分类问题。
* 感知器的神经元之间通过权重传递信息，权重的变化更加误差来进行调节。
* 感知器不能解决以异或为代表的线性不可分问题。

### 多层感知器 (需要重新查阅)

### 颈向基函数的神经网络(需要重新查阅)

### 自组织特征映射(需要重新查阅)

>1、将高维的输入数据映射到低维空间上，起到降维作用
* 训练过程
  * 竞争过程
    * 找到输入模式与神经元之间的最佳匹配
    * 内积最大化
  * 合作过程
    * 定界中心之外的拓扑邻域
  * 自适应过程
    * 排序过程
    * 收敛阶段
* 应用
  * 图像处理中检测和表述语义目标和目标类之间的存在关系
  * 自然语言中单词的语言规则
  
### 模糊神经网络

* 模糊神经网络是神经网络和模糊逻辑结合形成的混合智能系统
* 模糊神经网络的输入信号、权重系数和输出信号都是模糊集合
* 模糊神经网络的主要学习算法包括基于水平集的方法和基于遗传算法的方法
* 模糊神经网络具有和传统神经网络类似的通用逼近特性

## 深度学习

> 深度学习实际上是具有多个隐藏层的神经网络。

### 深度前馈网络(需要重新查阅) [重点、重要]

> 网络架构的建立？
> 损失函数的选择？
> 输出单元和隐藏单元的设计？
> 训练误差的处理？

* 深度前馈网络利用深度架构实现工程上的可实现的对任意函数的通用逼近
  * 逼近定理：如果一个前馈网络具有单个隐藏层，且这个隐藏层又有足够但是有限数目的神经元，那么这个神经网络就可以以任意精度逼近任意连续函数。
  * 使用深度架构的模型既能减少表示目标函数时所需要的单元数量，也能有效降低泛化误差，在一定程度上抑制过拟合的发生。
  * 待学习的复杂函数可以视为若干个简单函数的层次化结合。
  * 常用的连接方式：全连接
* 深度前馈网络使用梯度下降到方法进行学习
  * 梯度信息
  * 反向传播方法
  * 随机梯度下降法
* 深度前馈网络的损失函数通常是交叉熵或最小均方误差
  * 回归问题：最小均方差
  * 分类问题：交叉熵
  * 变换函数：线性变换、对数几率函数，softmax函数
* 深度前馈网络的隐藏神经元通常使用整流性单元作为传递函数
  * 整流线性单元
    * 渗漏整流单元（Leaky ReLU）
    * 指数整流单元（Exponential ReLU）

### 深度学习中的正则化(需要重新查阅) [重点、重要]

 > 正则化就是一类通过显式设计降低泛化误差，以提升算法通用性的策略的统称。

### 深度学习中的正则化

### 深度学习中的优化问题(需要重新查阅) [重点、重要]

* 面临的问题：
  * 病态矩阵（ill-conditioned matrix）
  * 局部极小值
  * 鞍点（saddle point）
* 随机梯度下降法 改进
  * 随机降低噪声
    * 动态采样、梯度聚合：
      * 通过使用固定的步长来获得线性的收敛速度，进而实现降噪
    * 迭代平均
      * 对每次迭代得到的参数结果求平均
  * 使用二阶导数
    * 拟牛顿法、高斯牛顿法、无Hessian牛顿法
  * 动量法（momentum）
  * 加速下降法（accelerated gradient descent）
  * 坐标下降法（coordinate descent）

### 自编码器(需要重新查阅)

### 深度强学习[重点、重要]

> 强化学习（reinforcement learning）实质上是智能系统从环境到行为的学习过程，智能体通过与环境的互动来改善自身的行为，改善准则是使某个累计奖励函数最大化。

* 强化学习最常用的模式：马尔可夫决策过程
  * 由离散时间随机控制的过程。
    * $S$: 由智能体和环境所处的所有**可能状态**构成的有限集合
    * $A$: 由智能体的所有**可能动作**构成的有限集合
    * $P_a(s,s^\prime) = Pr(s_{t+1} = s^\prime|s_t = s,a_t = a)$: 智能体在t时刻做出的动作$a$ 使马尔可夫过程的状态从$t$ 时刻的$s$转移为$t+1$时刻的$s^\prime$的概率
    * $R_a(s,s^\prime)$:智能体通过动作$a$使状态从$s$转移到$s^\prime$得到的实时奖励
  * 深度强化学习（deep reinforcement learning) 是深度学习和强化学习的结合，它将深度学习的感知能力和强化学习的决策能力融于一炉，用深度学习的运行机制达到强化学习的优化目的。
    * 基于价值
      * 建立一个价值函数
        * Q 学习算法： 用神经网络来训练Q算法的参数。
          * 经验回放
          * 目标Q网络
    * 基于策略
      * 直接搜索能使未来奖励最大化的最优策略。
        * 无监督强化辅助学习（UNREAL 算法）
    * 基于模型
      * 构建关于环境的模型
      * 用这个模型去指导策略
  
### 深度信念网络

### 卷积神经网络

### 循环神经网络

### 生成式对抗网络

### 长短期记忆网络

### 概率图模型

### 集群智能

### 迁移学习

### 知识图谱

### 应用场景

#### 计算机视觉

#### 语言处理

#### 机器翻译
